{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import FloatTensor\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import data_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded to car.csv\n",
      "Weights before training and testing: \n",
      "OrderedDict([('gate1Wz1', tensor([[ 1.9269],\n",
      "        [ 1.4873],\n",
      "        [ 0.9007],\n",
      "        [-2.1055],\n",
      "        [ 0.6784],\n",
      "        [ 1.0783],\n",
      "        [ 0.8008],\n",
      "        [ 1.6806],\n",
      "        [ 0.3559],\n",
      "        [-0.6866],\n",
      "        [-0.4934],\n",
      "        [ 0.2415],\n",
      "        [-1.1109],\n",
      "        [ 0.0418],\n",
      "        [-0.2516],\n",
      "        [ 0.8599],\n",
      "        [-0.3097],\n",
      "        [-0.3957],\n",
      "        [ 0.8034],\n",
      "        [-0.6216],\n",
      "        [-0.5920]])), ('gate1Wz2', tensor([[-0.4245],\n",
      "        [ 0.3057],\n",
      "        [-0.7746],\n",
      "        [ 0.0349],\n",
      "        [ 0.3211],\n",
      "        [ 1.8113],\n",
      "        [ 0.1606],\n",
      "        [ 0.3672],\n",
      "        [ 0.1754],\n",
      "        [ 1.3852],\n",
      "        [-0.4459],\n",
      "        [ 1.4451],\n",
      "        [ 0.8564],\n",
      "        [-1.0759],\n",
      "        [ 0.5357],\n",
      "        [ 1.1754],\n",
      "        [ 0.5612],\n",
      "        [-0.4527],\n",
      "        [-0.7718],\n",
      "        [-0.1722],\n",
      "        [ 0.5238]])), ('gate1Wx', tensor([[ 8.6540e-03],\n",
      "        [-1.4229e-01],\n",
      "        [ 1.9707e-01],\n",
      "        [-1.1441e+00],\n",
      "        [ 3.3832e-01],\n",
      "        [ 4.7466e-01],\n",
      "        [-2.5095e+00],\n",
      "        [ 4.8800e-01],\n",
      "        [ 7.8459e-01],\n",
      "        [ 2.8647e-02],\n",
      "        [ 6.4076e-01],\n",
      "        [ 5.8325e-01],\n",
      "        [ 1.0669e+00],\n",
      "        [ 5.5263e-01],\n",
      "        [-1.8527e-01],\n",
      "        [ 7.5276e-01],\n",
      "        [ 4.0476e-01],\n",
      "        [ 1.7847e-01],\n",
      "        [ 2.6491e-01],\n",
      "        [ 1.2732e+00],\n",
      "        [-1.3109e-03]])), ('gate1Wy', tensor([[ 0.4098],\n",
      "        [-1.4570],\n",
      "        [-0.1023],\n",
      "        [-0.5992],\n",
      "        [ 0.4771],\n",
      "        [-0.1360],\n",
      "        [ 1.6354],\n",
      "        [ 0.6547],\n",
      "        [ 0.5760],\n",
      "        [-0.3609],\n",
      "        [-0.0606],\n",
      "        [ 0.0733],\n",
      "        [ 0.8187],\n",
      "        [-0.3753],\n",
      "        [ 1.0331],\n",
      "        [-0.6867],\n",
      "        [ 0.6368],\n",
      "        [ 0.2176],\n",
      "        [-0.0467],\n",
      "        [-1.4335],\n",
      "        [-0.5665]])), ('gate2Wz1', tensor([[ 0.2695],\n",
      "        [-0.2104],\n",
      "        [-0.7328],\n",
      "        [ 0.1043],\n",
      "        [ 1.0414],\n",
      "        [-0.3095],\n",
      "        [ 0.5712],\n",
      "        [ 1.1179],\n",
      "        [-1.2956],\n",
      "        [ 0.0503],\n",
      "        [-0.5855],\n",
      "        [-0.3900],\n",
      "        [ 0.0358],\n",
      "        [-0.6401],\n",
      "        [-0.4908],\n",
      "        [ 0.2080],\n",
      "        [-1.1586],\n",
      "        [-0.9637],\n",
      "        [-0.3750],\n",
      "        [ 0.8033],\n",
      "        [-0.5188]])), ('gate2Wz2', tensor([[ 1.5335],\n",
      "        [-1.4510],\n",
      "        [-0.7861],\n",
      "        [-0.9563],\n",
      "        [-1.2476],\n",
      "        [-0.5778],\n",
      "        [ 0.3255],\n",
      "        [-0.8146],\n",
      "        [-1.0212],\n",
      "        [-0.4949],\n",
      "        [-0.5923],\n",
      "        [ 0.1543],\n",
      "        [ 0.4408],\n",
      "        [ 0.3125],\n",
      "        [-0.0335],\n",
      "        [-0.3980],\n",
      "        [ 1.0805],\n",
      "        [-1.7809],\n",
      "        [ 1.5080],\n",
      "        [ 0.3094],\n",
      "        [-0.5003]])), ('gate2Wx', tensor([[ 0.6630],\n",
      "        [ 0.7047],\n",
      "        [-0.0045],\n",
      "        [ 1.6668],\n",
      "        [ 0.1539],\n",
      "        [ 0.4626],\n",
      "        [-0.8719],\n",
      "        [-0.0271],\n",
      "        [-0.3532],\n",
      "        [ 1.4639],\n",
      "        [ 0.1729],\n",
      "        [ 1.0514],\n",
      "        [ 0.0075],\n",
      "        [ 0.5130],\n",
      "        [ 0.5397],\n",
      "        [ 0.5655],\n",
      "        [ 0.5058],\n",
      "        [ 0.2225],\n",
      "        [-0.9143],\n",
      "        [ 1.4840],\n",
      "        [-0.9109]])), ('gate2Wy', tensor([[-1.6107],\n",
      "        [-1.4790],\n",
      "        [ 0.4323],\n",
      "        [-0.1250],\n",
      "        [ 0.7821],\n",
      "        [ 0.8637],\n",
      "        [-0.5890],\n",
      "        [-1.0340],\n",
      "        [-0.2179],\n",
      "        [ 0.7987],\n",
      "        [ 0.9105],\n",
      "        [-0.0880],\n",
      "        [ 0.3370],\n",
      "        [-0.4808],\n",
      "        [ 0.3163],\n",
      "        [ 0.3866],\n",
      "        [ 0.7337],\n",
      "        [ 0.2510],\n",
      "        [ 0.0770],\n",
      "        [-0.2063],\n",
      "        [ 2.1698]])), ('gate3Wz1', tensor([[ 0.5230],\n",
      "        [ 0.9717],\n",
      "        [-0.2779],\n",
      "        [-0.6116],\n",
      "        [-0.5572],\n",
      "        [ 2.5574],\n",
      "        [ 0.5716],\n",
      "        [ 1.3596],\n",
      "        [ 0.4334],\n",
      "        [-0.7172],\n",
      "        [ 1.0554],\n",
      "        [-1.4534],\n",
      "        [ 0.4652],\n",
      "        [ 1.8350],\n",
      "        [ 0.8800],\n",
      "        [ 0.0561],\n",
      "        [ 0.3782],\n",
      "        [ 0.7051],\n",
      "        [-1.7237],\n",
      "        [-0.8435],\n",
      "        [ 0.4351]])), ('gate3Wz2', tensor([[-0.3360],\n",
      "        [ 0.0367],\n",
      "        [ 0.4934],\n",
      "        [ 0.8854],\n",
      "        [ 0.1824],\n",
      "        [ 0.0879],\n",
      "        [-1.2415],\n",
      "        [-0.3203],\n",
      "        [-0.8444],\n",
      "        [-0.5513],\n",
      "        [ 1.9890],\n",
      "        [ 0.8479],\n",
      "        [-0.6953],\n",
      "        [ 0.0281],\n",
      "        [-0.1754],\n",
      "        [-1.7735],\n",
      "        [-0.7046],\n",
      "        [-0.3947],\n",
      "        [ 1.8868],\n",
      "        [ 0.1787],\n",
      "        [-0.0385]])), ('gate3Wx', tensor([[ 2.1442],\n",
      "        [ 1.7046],\n",
      "        [ 0.3459],\n",
      "        [ 0.6425],\n",
      "        [-0.2040],\n",
      "        [-0.0996],\n",
      "        [-1.2311],\n",
      "        [ 0.8657],\n",
      "        [-1.4236],\n",
      "        [-0.6961],\n",
      "        [-0.3182],\n",
      "        [ 1.2154],\n",
      "        [ 1.4200],\n",
      "        [ 0.8244],\n",
      "        [ 1.4862],\n",
      "        [-1.4091],\n",
      "        [-0.3639],\n",
      "        [-0.0993],\n",
      "        [ 0.3105],\n",
      "        [ 0.3715],\n",
      "        [ 0.2697]])), ('gate3Wy', tensor([[-0.0388],\n",
      "        [-0.2130],\n",
      "        [-0.5904],\n",
      "        [ 0.4668],\n",
      "        [ 0.3956],\n",
      "        [-0.3016],\n",
      "        [-1.4033],\n",
      "        [-1.3271],\n",
      "        [-0.9948],\n",
      "        [-0.4940],\n",
      "        [ 1.1366],\n",
      "        [-0.4618],\n",
      "        [ 1.4200],\n",
      "        [ 0.8211],\n",
      "        [-0.0675],\n",
      "        [ 0.9491],\n",
      "        [-0.3983],\n",
      "        [ 0.6899],\n",
      "        [-1.3129],\n",
      "        [ 0.0378],\n",
      "        [-1.1702]])), ('gate4Wz1', tensor([[ 2.3664e+00],\n",
      "        [-6.3234e-01],\n",
      "        [-3.6152e-01],\n",
      "        [-1.6917e+00],\n",
      "        [-1.3839e+00],\n",
      "        [-6.8369e-01],\n",
      "        [ 6.6043e-02],\n",
      "        [-7.7380e-04],\n",
      "        [ 1.6206e-01],\n",
      "        [ 1.1960e+00],\n",
      "        [-1.3062e+00],\n",
      "        [-1.4040e+00],\n",
      "        [ 9.5265e-02],\n",
      "        [ 3.0573e-01],\n",
      "        [ 4.1506e-01],\n",
      "        [-7.1741e-01],\n",
      "        [ 2.8340e+00],\n",
      "        [ 1.9535e+00],\n",
      "        [ 2.0487e+00],\n",
      "        [-1.0880e+00],\n",
      "        [-2.0479e+00]])), ('gate4Wz2', tensor([[ 0.8513],\n",
      "        [-0.4005],\n",
      "        [-0.6088],\n",
      "        [-0.5081],\n",
      "        [-0.6185],\n",
      "        [-1.2823],\n",
      "        [ 1.9653],\n",
      "        [-1.1766],\n",
      "        [ 1.1889],\n",
      "        [ 0.2156],\n",
      "        [ 0.6265],\n",
      "        [ 0.9144],\n",
      "        [ 1.0095],\n",
      "        [-0.3389],\n",
      "        [ 0.5180],\n",
      "        [-1.7459],\n",
      "        [ 1.0964],\n",
      "        [ 0.4866],\n",
      "        [ 0.3668],\n",
      "        [-0.3912],\n",
      "        [ 0.1699]])), ('gate4Wx', tensor([[-0.7252],\n",
      "        [-0.9528],\n",
      "        [-0.8428],\n",
      "        [-1.6413],\n",
      "        [-0.7181],\n",
      "        [ 1.6612],\n",
      "        [ 0.5439],\n",
      "        [-0.5214],\n",
      "        [-0.7576],\n",
      "        [-0.0756],\n",
      "        [-1.7376],\n",
      "        [-0.1254],\n",
      "        [-1.3658],\n",
      "        [-1.4078],\n",
      "        [-0.3764],\n",
      "        [ 0.9874],\n",
      "        [ 0.6415],\n",
      "        [-1.3313],\n",
      "        [ 2.0071],\n",
      "        [-1.2531],\n",
      "        [ 1.1189]])), ('gate4Wy', tensor([[ 0.5361],\n",
      "        [ 0.9226],\n",
      "        [ 0.4872],\n",
      "        [ 1.4920],\n",
      "        [ 0.0133],\n",
      "        [-0.8032],\n",
      "        [-1.1209],\n",
      "        [ 0.1956],\n",
      "        [-0.7815],\n",
      "        [-1.7899],\n",
      "        [-0.2616],\n",
      "        [-0.4403],\n",
      "        [ 2.1848],\n",
      "        [-0.4801],\n",
      "        [-1.2872],\n",
      "        [ 0.7389],\n",
      "        [ 0.0339],\n",
      "        [-0.3123],\n",
      "        [-0.2542],\n",
      "        [-1.2055],\n",
      "        [-0.9542]]))])\n",
      "Weights after training and testing:\n",
      "OrderedDict([('gate1Wz1', tensor([[ 1.9269],\n",
      "        [ 1.4873],\n",
      "        [ 0.9007],\n",
      "        [-2.1055],\n",
      "        [ 0.6784],\n",
      "        [ 1.0783],\n",
      "        [ 0.8008],\n",
      "        [ 1.6806],\n",
      "        [ 0.3559],\n",
      "        [-0.6866],\n",
      "        [-0.4934],\n",
      "        [ 0.2415],\n",
      "        [-1.1109],\n",
      "        [ 0.0418],\n",
      "        [-0.2516],\n",
      "        [ 0.8599],\n",
      "        [-0.3097],\n",
      "        [-0.3957],\n",
      "        [ 0.8034],\n",
      "        [-0.6216],\n",
      "        [-0.5920]])), ('gate1Wz2', tensor([[-0.4245],\n",
      "        [ 0.3057],\n",
      "        [-0.7746],\n",
      "        [ 0.0349],\n",
      "        [ 0.3211],\n",
      "        [ 1.8113],\n",
      "        [ 0.1606],\n",
      "        [ 0.3672],\n",
      "        [ 0.1754],\n",
      "        [ 1.3852],\n",
      "        [-0.4459],\n",
      "        [ 1.4451],\n",
      "        [ 0.8564],\n",
      "        [-1.0759],\n",
      "        [ 0.5357],\n",
      "        [ 1.1754],\n",
      "        [ 0.5612],\n",
      "        [-0.4527],\n",
      "        [-0.7718],\n",
      "        [-0.1722],\n",
      "        [ 0.5238]])), ('gate1Wx', tensor([[ 8.6540e-03],\n",
      "        [-1.4229e-01],\n",
      "        [ 1.9707e-01],\n",
      "        [-1.1441e+00],\n",
      "        [ 3.3832e-01],\n",
      "        [ 4.7466e-01],\n",
      "        [-2.5095e+00],\n",
      "        [ 4.8800e-01],\n",
      "        [ 7.8459e-01],\n",
      "        [ 2.8647e-02],\n",
      "        [ 6.4076e-01],\n",
      "        [ 5.8325e-01],\n",
      "        [ 1.0669e+00],\n",
      "        [ 5.5263e-01],\n",
      "        [-1.8527e-01],\n",
      "        [ 7.5276e-01],\n",
      "        [ 4.0476e-01],\n",
      "        [ 1.7847e-01],\n",
      "        [ 2.6491e-01],\n",
      "        [ 1.2732e+00],\n",
      "        [-1.3109e-03]])), ('gate1Wy', tensor([[ 0.4098],\n",
      "        [-1.4570],\n",
      "        [-0.1023],\n",
      "        [-0.5992],\n",
      "        [ 0.4771],\n",
      "        [-0.1360],\n",
      "        [ 1.6354],\n",
      "        [ 0.6547],\n",
      "        [ 0.5760],\n",
      "        [-0.3609],\n",
      "        [-0.0606],\n",
      "        [ 0.0733],\n",
      "        [ 0.8187],\n",
      "        [-0.3753],\n",
      "        [ 1.0331],\n",
      "        [-0.6867],\n",
      "        [ 0.6368],\n",
      "        [ 0.2176],\n",
      "        [-0.0467],\n",
      "        [-1.4335],\n",
      "        [-0.5665]])), ('gate2Wz1', tensor([[ 0.2695],\n",
      "        [-0.2104],\n",
      "        [-0.7328],\n",
      "        [ 0.1043],\n",
      "        [ 1.0414],\n",
      "        [-0.3095],\n",
      "        [ 0.5712],\n",
      "        [ 1.1179],\n",
      "        [-1.2956],\n",
      "        [ 0.0503],\n",
      "        [-0.5855],\n",
      "        [-0.3900],\n",
      "        [ 0.0358],\n",
      "        [-0.6401],\n",
      "        [-0.4908],\n",
      "        [ 0.2080],\n",
      "        [-1.1586],\n",
      "        [-0.9637],\n",
      "        [-0.3750],\n",
      "        [ 0.8033],\n",
      "        [-0.5188]])), ('gate2Wz2', tensor([[ 1.5335],\n",
      "        [-1.4510],\n",
      "        [-0.7861],\n",
      "        [-0.9563],\n",
      "        [-1.2476],\n",
      "        [-0.5778],\n",
      "        [ 0.3255],\n",
      "        [-0.8146],\n",
      "        [-1.0212],\n",
      "        [-0.4949],\n",
      "        [-0.5923],\n",
      "        [ 0.1543],\n",
      "        [ 0.4408],\n",
      "        [ 0.3125],\n",
      "        [-0.0335],\n",
      "        [-0.3980],\n",
      "        [ 1.0805],\n",
      "        [-1.7809],\n",
      "        [ 1.5080],\n",
      "        [ 0.3094],\n",
      "        [-0.5003]])), ('gate2Wx', tensor([[ 0.6630],\n",
      "        [ 0.7047],\n",
      "        [-0.0045],\n",
      "        [ 1.6668],\n",
      "        [ 0.1539],\n",
      "        [ 0.4626],\n",
      "        [-0.8719],\n",
      "        [-0.0271],\n",
      "        [-0.3532],\n",
      "        [ 1.4639],\n",
      "        [ 0.1729],\n",
      "        [ 1.0514],\n",
      "        [ 0.0075],\n",
      "        [ 0.5130],\n",
      "        [ 0.5397],\n",
      "        [ 0.5655],\n",
      "        [ 0.5058],\n",
      "        [ 0.2225],\n",
      "        [-0.9143],\n",
      "        [ 1.4840],\n",
      "        [-0.9109]])), ('gate2Wy', tensor([[-1.6107],\n",
      "        [-1.4790],\n",
      "        [ 0.4323],\n",
      "        [-0.1250],\n",
      "        [ 0.7821],\n",
      "        [ 0.8637],\n",
      "        [-0.5890],\n",
      "        [-1.0340],\n",
      "        [-0.2179],\n",
      "        [ 0.7987],\n",
      "        [ 0.9105],\n",
      "        [-0.0880],\n",
      "        [ 0.3370],\n",
      "        [-0.4808],\n",
      "        [ 0.3163],\n",
      "        [ 0.3866],\n",
      "        [ 0.7337],\n",
      "        [ 0.2510],\n",
      "        [ 0.0770],\n",
      "        [-0.2063],\n",
      "        [ 2.1698]])), ('gate3Wz1', tensor([[ 0.5230],\n",
      "        [ 0.9717],\n",
      "        [-0.2779],\n",
      "        [-0.6116],\n",
      "        [-0.5572],\n",
      "        [ 2.5574],\n",
      "        [ 0.5716],\n",
      "        [ 1.3596],\n",
      "        [ 0.4334],\n",
      "        [-0.7172],\n",
      "        [ 1.0554],\n",
      "        [-1.4534],\n",
      "        [ 0.4652],\n",
      "        [ 1.8350],\n",
      "        [ 0.8800],\n",
      "        [ 0.0561],\n",
      "        [ 0.3782],\n",
      "        [ 0.7051],\n",
      "        [-1.7237],\n",
      "        [-0.8435],\n",
      "        [ 0.4351]])), ('gate3Wz2', tensor([[-0.3360],\n",
      "        [ 0.0367],\n",
      "        [ 0.4934],\n",
      "        [ 0.8854],\n",
      "        [ 0.1824],\n",
      "        [ 0.0879],\n",
      "        [-1.2415],\n",
      "        [-0.3203],\n",
      "        [-0.8444],\n",
      "        [-0.5513],\n",
      "        [ 1.9890],\n",
      "        [ 0.8479],\n",
      "        [-0.6953],\n",
      "        [ 0.0281],\n",
      "        [-0.1754],\n",
      "        [-1.7735],\n",
      "        [-0.7046],\n",
      "        [-0.3947],\n",
      "        [ 1.8868],\n",
      "        [ 0.1787],\n",
      "        [-0.0385]])), ('gate3Wx', tensor([[ 2.1442],\n",
      "        [ 1.7046],\n",
      "        [ 0.3459],\n",
      "        [ 0.6425],\n",
      "        [-0.2040],\n",
      "        [-0.0996],\n",
      "        [-1.2311],\n",
      "        [ 0.8657],\n",
      "        [-1.4236],\n",
      "        [-0.6961],\n",
      "        [-0.3182],\n",
      "        [ 1.2154],\n",
      "        [ 1.4200],\n",
      "        [ 0.8244],\n",
      "        [ 1.4862],\n",
      "        [-1.4091],\n",
      "        [-0.3639],\n",
      "        [-0.0993],\n",
      "        [ 0.3105],\n",
      "        [ 0.3715],\n",
      "        [ 0.2697]])), ('gate3Wy', tensor([[-0.0388],\n",
      "        [-0.2130],\n",
      "        [-0.5904],\n",
      "        [ 0.4668],\n",
      "        [ 0.3956],\n",
      "        [-0.3016],\n",
      "        [-1.4033],\n",
      "        [-1.3271],\n",
      "        [-0.9948],\n",
      "        [-0.4940],\n",
      "        [ 1.1366],\n",
      "        [-0.4618],\n",
      "        [ 1.4200],\n",
      "        [ 0.8211],\n",
      "        [-0.0675],\n",
      "        [ 0.9491],\n",
      "        [-0.3983],\n",
      "        [ 0.6899],\n",
      "        [-1.3129],\n",
      "        [ 0.0378],\n",
      "        [-1.1702]])), ('gate4Wz1', tensor([[ 2.3664e+00],\n",
      "        [-6.3234e-01],\n",
      "        [-3.6152e-01],\n",
      "        [-1.6917e+00],\n",
      "        [-1.3839e+00],\n",
      "        [-6.8369e-01],\n",
      "        [ 6.6043e-02],\n",
      "        [-7.7380e-04],\n",
      "        [ 1.6206e-01],\n",
      "        [ 1.1960e+00],\n",
      "        [-1.3062e+00],\n",
      "        [-1.4040e+00],\n",
      "        [ 9.5265e-02],\n",
      "        [ 3.0573e-01],\n",
      "        [ 4.1506e-01],\n",
      "        [-7.1741e-01],\n",
      "        [ 2.8340e+00],\n",
      "        [ 1.9535e+00],\n",
      "        [ 2.0487e+00],\n",
      "        [-1.0880e+00],\n",
      "        [-2.0479e+00]])), ('gate4Wz2', tensor([[ 0.8513],\n",
      "        [-0.4005],\n",
      "        [-0.6088],\n",
      "        [-0.5081],\n",
      "        [-0.6185],\n",
      "        [-1.2823],\n",
      "        [ 1.9653],\n",
      "        [-1.1766],\n",
      "        [ 1.1889],\n",
      "        [ 0.2156],\n",
      "        [ 0.6265],\n",
      "        [ 0.9144],\n",
      "        [ 1.0095],\n",
      "        [-0.3389],\n",
      "        [ 0.5180],\n",
      "        [-1.7459],\n",
      "        [ 1.0964],\n",
      "        [ 0.4866],\n",
      "        [ 0.3668],\n",
      "        [-0.3912],\n",
      "        [ 0.1699]])), ('gate4Wx', tensor([[-0.7252],\n",
      "        [-0.9528],\n",
      "        [-0.8428],\n",
      "        [-1.6413],\n",
      "        [-0.7181],\n",
      "        [ 1.6612],\n",
      "        [ 0.5439],\n",
      "        [-0.5214],\n",
      "        [-0.7576],\n",
      "        [-0.0756],\n",
      "        [-1.7376],\n",
      "        [-0.1254],\n",
      "        [-1.3658],\n",
      "        [-1.4078],\n",
      "        [-0.3764],\n",
      "        [ 0.9874],\n",
      "        [ 0.6415],\n",
      "        [-1.3313],\n",
      "        [ 2.0071],\n",
      "        [-1.2531],\n",
      "        [ 1.1189]])), ('gate4Wy', tensor([[ 0.5361],\n",
      "        [ 0.9226],\n",
      "        [ 0.4872],\n",
      "        [ 1.4920],\n",
      "        [ 0.0133],\n",
      "        [-0.8032],\n",
      "        [-1.1209],\n",
      "        [ 0.1956],\n",
      "        [-0.7815],\n",
      "        [-1.7899],\n",
      "        [-0.2616],\n",
      "        [-0.4403],\n",
      "        [ 2.1848],\n",
      "        [-0.4801],\n",
      "        [-1.2872],\n",
      "        [ 0.7389],\n",
      "        [ 0.0339],\n",
      "        [-0.3123],\n",
      "        [-0.2542],\n",
      "        [-1.2055],\n",
      "        [-0.9542]]))])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = data_processing.load_data(download=True)\n",
    "new_data = data_processing.convert2onehot(data)\n",
    "\n",
    "# prepare training data\n",
    "new_data = new_data.values.astype(np.float32)       # change to numpy array and float32\n",
    "np.random.shuffle(new_data) # shuffles the data\n",
    "sep = int(0.7*len(new_data)) # separate data [70% mark]\n",
    "train_data = new_data[:sep]                         # training data (70%)\n",
    "test_data = new_data[sep:]                          # test data (30%)\n",
    "\n",
    "x_train = torch.from_numpy(train_data[:, :21])\n",
    "y_train = torch.from_numpy(train_data[:, 21:]) # creating tensors for pytorch\n",
    "\n",
    "x_test = torch.from_numpy(test_data[:, :21])\n",
    "y_test = torch.from_numpy(test_data[:, 21:]) # ^^^\n",
    "\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(dataset = train_data, batch_size = 1) # create batches\n",
    "\n",
    "test_data = TensorDataset(x_test, y_test)\n",
    "test_loader = DataLoader(dataset = test_data, batch_size = 1) # create batches\n",
    "\n",
    "# trying out and gate\n",
    "class andgate(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "#        Dict = {}        \n",
    "#        def generateParameters():\n",
    "\n",
    "        inputSize = 21\n",
    "        hiddenSize = 1\n",
    "        # have to generate parameters and add bias [will do this later]\n",
    "        self.gate1Wz1 = nn.Parameter(torch.randn(inputSize, hiddenSize, requires_grad=True, dtype=torch.float))\n",
    "        self.gate1Wz2 = nn.Parameter(torch.randn(inputSize, hiddenSize, requires_grad=True, dtype=torch.float))\n",
    "        self.gate1Wx = nn.Parameter(torch.randn(inputSize, hiddenSize, requires_grad=True, dtype=torch.float))\n",
    "        self.gate1Wy = nn.Parameter(torch.randn(inputSize, hiddenSize, requires_grad=True, dtype=torch.float))\n",
    "        self.gate2Wz1 = nn.Parameter(torch.randn(inputSize, hiddenSize, requires_grad=True, dtype=torch.float))\n",
    "        self.gate2Wz2 = nn.Parameter(torch.randn(inputSize, hiddenSize, requires_grad=True, dtype=torch.float))\n",
    "        self.gate2Wx = nn.Parameter(torch.randn(inputSize, hiddenSize, requires_grad=True, dtype=torch.float))\n",
    "        self.gate2Wy = nn.Parameter(torch.randn(inputSize, hiddenSize, requires_grad=True, dtype=torch.float))\n",
    "        self.gate3Wz1 = nn.Parameter(torch.randn(inputSize, hiddenSize, requires_grad=True, dtype=torch.float))\n",
    "        self.gate3Wz2 = nn.Parameter(torch.randn(inputSize, hiddenSize, requires_grad=True, dtype=torch.float))\n",
    "        self.gate3Wx = nn.Parameter(torch.randn(inputSize, hiddenSize, requires_grad=True, dtype=torch.float))\n",
    "        self.gate3Wy = nn.Parameter(torch.randn(inputSize, hiddenSize, requires_grad=True, dtype=torch.float))\n",
    "        self.gate4Wz1 = nn.Parameter(torch.randn(inputSize, hiddenSize, requires_grad=True, dtype=torch.float))\n",
    "        self.gate4Wz2 = nn.Parameter(torch.randn(inputSize, hiddenSize, requires_grad=True, dtype=torch.float))\n",
    "        self.gate4Wx = nn.Parameter(torch.randn(inputSize, hiddenSize, requires_grad=True, dtype=torch.float))\n",
    "        self.gate4Wy = nn.Parameter(torch.randn(inputSize, hiddenSize, requires_grad=True, dtype=torch.float))\n",
    "                    \n",
    "        \n",
    "    def forward(self, X):\n",
    "        def gate1():            \n",
    "            # z1 is the first input [sum the values]\n",
    "            z1 = torch.matmul(X, self.gate1Wz1)\n",
    "            \n",
    "            # z2 is the second input [sum the values]\n",
    "            z2 = torch.matmul(X, self.gate1Wz2)\n",
    "            \n",
    "            # x is one possible output [sum the values]\n",
    "            def x():\n",
    "                x = torch.matmul(X, self.gate1Wx)\n",
    "                return x# + bx\n",
    "\n",
    "            # y is one possible output [sum the values]\n",
    "            def y():\n",
    "                y = torch.matmul(X, self.gate1Wy)\n",
    "                return y #+ by\n",
    "\n",
    "            def firstgate():\n",
    "                if(z1 < 0):\n",
    "                    result = x()\n",
    "                else:\n",
    "                    result = y()\n",
    "                return result\n",
    "\n",
    "            def secondgate():\n",
    "                if(z2 < 0):\n",
    "                    result = firstgate()\n",
    "                else:\n",
    "                    result = y()\n",
    "                return result\n",
    "\n",
    "            output = secondgate()\n",
    "            return output\n",
    "        \n",
    "        def gate2():            \n",
    "            # z1 is the first input [sum the values]\n",
    "            z1 = torch.matmul(X, self.gate2Wz1)\n",
    "           \n",
    "            # z2 is the second input [sum the values]\n",
    "            z2 = torch.matmul(X, self.gate2Wz2)\n",
    "           \n",
    "            # x is one possible output [sum the values]\n",
    "            def x():\n",
    "                x = torch.matmul(X, self.gate2Wx)\n",
    "                return x# + bx\n",
    "\n",
    "            # y is one possible output [sum the values]\n",
    "            def y():\n",
    "                y = torch.matmul(X, self.gate2Wy)\n",
    "                return y #+ by\n",
    "\n",
    "            def firstgate():\n",
    "                if(z1 < 0):\n",
    "                    result = x()\n",
    "                else:\n",
    "                    result = y()\n",
    "                return result\n",
    "\n",
    "            def secondgate():\n",
    "                if(z2 < 0):\n",
    "                    result = firstgate()\n",
    "                else:\n",
    "                    result = y()\n",
    "                return result\n",
    "\n",
    "            output = secondgate()\n",
    "            return output\n",
    "\n",
    "        def gate3():            \n",
    "            # z1 is the first input [sum the values]\n",
    "            z1 = torch.matmul(X, self.gate3Wz1)\n",
    "           \n",
    "            # z2 is the second input [sum the values]\n",
    "            z2 = torch.matmul(X, self.gate3Wz2)\n",
    "           \n",
    "            # x is one possible output [sum the values]\n",
    "            def x():\n",
    "                x = torch.matmul(X, self.gate3Wx)\n",
    "                return x# + bx\n",
    "\n",
    "            # y is one possible output [sum the values]\n",
    "            def y():\n",
    "                y = torch.matmul(X, self.gate3Wy)\n",
    "                return y #+ by\n",
    "\n",
    "            def firstgate():\n",
    "                if(z1 < 0):\n",
    "                    result = x()\n",
    "                else:\n",
    "                    result = y()\n",
    "                return result\n",
    "\n",
    "            def secondgate():\n",
    "                if(z2 < 0):\n",
    "                    result = firstgate()\n",
    "                else:\n",
    "                    result = y()\n",
    "                return result\n",
    "\n",
    "            output = secondgate()\n",
    "            return output\n",
    "            \n",
    "        def gate4():            \n",
    "            # z1 is the first input [sum the values]\n",
    "            z1 = torch.matmul(X, self.gate4Wz1)\n",
    "\n",
    "            # z2 is the second input [sum the values]\n",
    "            z2 = torch.matmul(X, self.gate4Wz2)\n",
    "\n",
    "            # x is one possible output [sum the values]\n",
    "            def x():\n",
    "                x = torch.matmul(X, self.gate4Wx)\n",
    "                return x# + bx\n",
    "\n",
    "            # y is one possible output [sum the values]\n",
    "            def y():\n",
    "                y = torch.matmul(X, self.gate4Wy)\n",
    "                return y #+ by\n",
    "\n",
    "            def firstgate():\n",
    "                if(z1 < 0):\n",
    "                    result = x()\n",
    "                else:\n",
    "                    result = y()\n",
    "                return result\n",
    "\n",
    "            def secondgate():\n",
    "                if(z2 < 0):\n",
    "                    result = firstgate()\n",
    "                else:\n",
    "                    result = y()\n",
    "                return result\n",
    "\n",
    "            output = secondgate()\n",
    "            return output\n",
    "        # result is just the 4 gates' results right now\n",
    "        results = [[gate1(), gate2(), gate3(), gate4()]]\n",
    "        output = torch.tensor(results, requires_grad = True)\n",
    "        return output\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model = andgate()\n",
    "print(\"Weights before training and testing: \")\n",
    "print(model.state_dict())\n",
    "\n",
    "lr = 1e-3\n",
    "n_epochs = 10\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction='mean') # loss function\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "def make_train_step(model, loss_fn, optimizer):\n",
    "    def train_step(X, y):\n",
    "        model.train()\n",
    "        yhat = model(X)\n",
    "        loss = loss_fn(yhat, y)\n",
    "        loss.backward(retain_graph = True)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        return loss.item()\n",
    "    return train_step\n",
    "\n",
    "train_step = make_train_step(model, loss_fn, optimizer)\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "plt.ion()\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n",
    "accuracies, steps = [], []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    steps.append(epoch)\n",
    "    \n",
    "    for x_batch, y_batch in train_loader:\n",
    "        loss = train_step(x_batch, y_batch)\n",
    "        losses.append(loss)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x_test, y_test in test_loader:\n",
    "            model.eval()\n",
    "            yhat = model(x_test)\n",
    "            test_loss = loss_fn(y_test, yhat)\n",
    "            val_losses.append(test_loss.item())\n",
    "        \n",
    "#         ax1.cla()\n",
    "#         ax1.set_xticks(range(4), [\"accepted\", \"good\", \"unaccepted\", \"very good\"])\n",
    "#         ax1.set_ylim((0, 400))\n",
    "#         ax2.cla()\n",
    "#         ax2.plot(steps, val_losses, label=\"accuracy\")\n",
    "#         ax2.set_ylim(ymax=1)\n",
    "#         ax2.set_ylabel(\"accuracy\")\n",
    "#         plt.pause(0.01)\n",
    "\n",
    "print(\"Weights after training and testing:\")\n",
    "print(model.state_dict())\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Ignore cell; from previous work.\n",
    "'''\n",
    "\n",
    "class GATES:\n",
    "    def __init__(self):\n",
    "        self.inputSize = 21\n",
    "        self.outputSize = 1\n",
    "        self.hiddenSize = 1209\n",
    "        \n",
    "        # weights [eventually want a set of different weights for each function]\n",
    "        self.Wz1 = Variable(torch.randn(self.inputSize, self.hiddenSize), requires_grad = True) # random weights for 25 x 1209 tensor. stores the parameters from the input to hidden layer;\n",
    "        self.bz1 = torch.randn(1, 1) # bias is a scalar\n",
    "        self.Wz2 = Variable(torch.randn(self.inputSize, self.hiddenSize), requires_grad = True) # random weights for 25 x 1209 tensor.\n",
    "        self.bz2 = torch.randn(1, 1) # bias is a scalar\n",
    "        self.Wx = Variable(torch.randn(self.inputSize, self.hiddenSize), requires_grad = True) # random weights for 25 x 1209 tensor\n",
    "        self.bX = torch.randn(1, 1) # bias is a scalar\n",
    "        self.Wy = Variable(torch.randn(self.inputSize, self.hiddenSize), requires_grad = True) # random weights for 25 x 1209 tensor\n",
    "        self.bY = torch.randn(1, 1) # bias is a scalar\n",
    "        \n",
    "        # ANDGATE\n",
    "    def andgate(self, X):\n",
    "        # z1 is the first input [sum the values]\n",
    "        z1 = torch.matmul(X, self.Wz1)\n",
    "        z1Sum = torch.sum(z1) + self.bz1\n",
    "            \n",
    "        # z2 is the second input [sum the values]\n",
    "        z2 = torch.matmul(X, self.Wz2)\n",
    "        z2Sum = torch.sum(z2) + self.bz2\n",
    "        \n",
    "        # x is one possible output [sum the values]\n",
    "        def x():\n",
    "            x = torch.matmul(X, self.Wx)\n",
    "            return torch.sum(x) + self.bX\n",
    "\n",
    "        # y is one possible output [sum the values]\n",
    "        def y():\n",
    "            y = torch.matmul(X, self.Wy)\n",
    "            return torch.sum(y) + self.bY\n",
    "\n",
    "        def firstgate():\n",
    "            if(z1Sum < 0):\n",
    "                result = x()\n",
    "            else:\n",
    "                result = y()\n",
    "            return result\n",
    "\n",
    "        def secondgate():\n",
    "            if(z2Sum < 0):\n",
    "                result = firstgate()\n",
    "            else:\n",
    "                result = y()\n",
    "            return result\n",
    "\n",
    "        return secondgate()\n",
    "\n",
    "    def notgate(self, X):\n",
    "\n",
    "        def x():\n",
    "            x = torch.matmul(X, self.Wx) + self.bX\n",
    "            return torch.sum(x)\n",
    "\n",
    "        def y():\n",
    "            y = torch.matmul(X, self.Wy) + self.bY\n",
    "            return torch.sum(y)\n",
    "\n",
    "        z1 = torch.matmul(X, self.Wz1) + self.bz1\n",
    "        z1Sum = torch.sum(z1)\n",
    "\n",
    "        if(z1Sum < 0):\n",
    "            result = y()\n",
    "\n",
    "        else:\n",
    "            result = x()\n",
    "        \n",
    "        return result\n",
    "\n",
    "        \n",
    "    def orgate(self, X):\n",
    "        \n",
    "        # z1 is the first input [sum the values]\n",
    "        z1 = torch.matmul(X, self.Wz1)\n",
    "        z1Sum = torch.sum(z1) + self.bz1\n",
    "            \n",
    "        # z2 is the second input [sum the values]\n",
    "        z2 = torch.matmul(X, self.Wz2)\n",
    "        z2Sum = torch.sum(z2) + self.bz2\n",
    "        \n",
    "        # x is one possible output [sum the values]\n",
    "        def x():\n",
    "            x = torch.matmul(X, self.Wx)\n",
    "            return torch.sum(x) + self.bX\n",
    "\n",
    "        # y is one possible output [sum the values]\n",
    "        def y():\n",
    "            y = torch.matmul(X, self.Wy)\n",
    "            return torch.sum(y) + self.bY\n",
    "\n",
    "        def firstgate():\n",
    "            if(z1Sum < 0):\n",
    "                result = x()\n",
    "            else:\n",
    "                result = y()\n",
    "            return result\n",
    "\n",
    "        def secondgate():\n",
    "            if(z2Sum < 0):\n",
    "                result = x()\n",
    "            else:\n",
    "                result = firstgate()\n",
    "            return result\n",
    "\n",
    "        return secondgate()\n",
    "        \n",
    "        \n",
    "o = GATES()\n",
    "andOutput = o.andgate(train_data_x)\n",
    "notOutput = o.notgate(train_data_x)\n",
    "orOutput = o.orgate(train_data_x)\n",
    "\n",
    "print(\"AND OUTPUT: \", andOutput)\n",
    "\n",
    "target = Variable(torch.randn(1, 1), requires_grad = True)  # a dummy target, for example\n",
    "print(\"TARGET IS: \", target)\n",
    "\n",
    "criterion = nn.MSELoss() # Simple Mean Squared Loss\n",
    "\n",
    "loss = criterion(andOutput, target)\n",
    "print(loss) # their loss function\n",
    "\n",
    "loss = Variable(loss, requires_grad = True)\n",
    "loss.backward()\n",
    "print(loss.grad.data)\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
    "print(a, b)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
